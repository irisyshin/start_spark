{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129c02a1-bd19-4668-8b3f-62e4f3ab84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e419cfa-8bd8-4fbd-97b1-650dde9243bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('json')\\\n",
    "        .load(\"learning_spark_data/2015-summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc459b8-4b43-48c2-bd11-7f251e47f1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DEST_COUNTRY_NAME', 'string'),\n",
       " ('ORIGIN_COUNTRY_NAME', 'string'),\n",
       " ('count', 'bigint')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03b4dfc-2341-4323-bab1-2128c09a655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6625ee4b-120e-4954-979c-b6a3af98cd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(3) #하나하나가 다 RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b048bf-b5e2-45ea-8181-0192ae7aa13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|   15|\n",
      "|    1|\n",
      "|  344|\n",
      "|   15|\n",
      "|   62|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('count').show(5) # 모양 형태 그대로 쓰고 싶으면 select 함수 씀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d863f7-6428-4b16-ab26-bd43fd3bb88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|         Anguilla|\n",
      "|           Russia|\n",
      "|         Paraguay|\n",
      "|          Senegal|\n",
      "|           Sweden|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# distinct(), 중복을 제거하는 함수 \n",
    "df.select('DEST_COUNTRY_NAME').distinct().show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd88dabb-6bc4-4f01-87b8-c4e76f1a79f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cache(), 메모리에 올려두고 계속 써, 새로운 rdd 생성  x \n",
    "df1 = df.select('DEST_COUNTRY_NAME').distinct().cache()\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ecbf9b3-99b0-4879-83e8-dbcba6fd9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row class를 이용한 단일 record 생성 \n",
    "\n",
    "from pyspark.sql import Row\n",
    "myRow = Row('Hello', None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c4ef58-c097-4f61-8a76-77756dc7fd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint, withinCountry: boolean]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 컬럼 추가하기 \n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df3 = df.withColumn('withinCountry', expr('ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME')) #expr():표현식을 받아 생성 \n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13922598-26c5-46a2-ab12-03de385153a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|withinCountry|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "|    United States|      United States|370002|         true|\n",
      "+-----------------+-------------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.filter(df3.withinCountry == True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3180bca2-ddd2-4438-b0b6-dd77276aaf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+--------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|category|\n",
      "+--------------------+-------------------+-----+--------+\n",
      "|       United States|            Romania|   15|   upper|\n",
      "|       United States|            Croatia|    1|   under|\n",
      "|       United States|            Ireland|  344|   upper|\n",
      "|               Egypt|      United States|   15|   upper|\n",
      "|       United States|              India|   62|   upper|\n",
      "|       United States|          Singapore|    1|   under|\n",
      "|       United States|            Grenada|   62|   upper|\n",
      "|          Costa Rica|      United States|  588|   upper|\n",
      "|             Senegal|      United States|   40|   upper|\n",
      "|             Moldova|      United States|    1|   under|\n",
      "|       United States|       Sint Maarten|  325|   upper|\n",
      "|       United States|   Marshall Islands|   39|   upper|\n",
      "|              Guyana|      United States|   64|   upper|\n",
      "|               Malta|      United States|    1|   under|\n",
      "|            Anguilla|      United States|   41|   upper|\n",
      "|             Bolivia|      United States|   30|   upper|\n",
      "|       United States|           Paraguay|    6|   under|\n",
      "|             Algeria|      United States|    4|   under|\n",
      "|Turks and Caicos ...|      United States|  230|   upper|\n",
      "|       United States|          Gibraltar|    1|   under|\n",
      "+--------------------+-------------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case when 카운트 10 이하 under, 이상 upper로 변환 > category 컬럼 추가 \n",
    "\n",
    "# sql 표현식 \n",
    "df4 = df.withColumn( 'category', expr(\"CASE WHEN count <= 10 THEN 'under' ELSE 'upper' END\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef79d897-9cb8-45ec-a24e-7c6a1caab6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe의 select(), where(), filter() -> transformation\n",
    "#show(), count() -> action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff6c73b-89a0-4e55-8b45-26db1a7025dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp.csv 읽기\n",
    "emp_df = spark.read.csv(\n",
    "    \"learning_spark_data/emp.csv\",\n",
    "    header=True,       # 첫 행을 컬럼명으로 사용\n",
    "    inferSchema=True   # 데이터 타입 자동 추론\n",
    ")\n",
    "\n",
    "# dept.csv 읽기\n",
    "dept_df = spark.read.csv(\n",
    "    \"learning_spark_data/dept.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1859f900-8019-4411-af58-b4d0ca71c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n",
      "+------+----------+--------+\n",
      "|deptno|     dname|     loc|\n",
      "+------+----------+--------+\n",
      "|    10|ACCOUNTING|NEW YORK|\n",
      "|    20|  RESEARCH|  DALLAS|\n",
      "|    30|     SALES| CHICAGO|\n",
      "|    40|OPERATIONS|  BOSTON|\n",
      "+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 확인\n",
    "emp_df.show()\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e05d12-1ad1-419c-948d-7829fa09648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: date (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- deptno: integer (nullable = true)\n",
      " |-- dname: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.printSchema()\n",
    "dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e29d252-a7de-4c81-b69f-fc78bcadbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.count(), dept_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63bb766-51be-4209-8041-6e449e2c39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| ENAME|DEPTNO|\n",
      "+------+------+\n",
      "| SMITH|    20|\n",
      "| ALLEN|    30|\n",
      "|  WARD|    30|\n",
      "| JONES|    20|\n",
      "|MARTIN|    30|\n",
      "| BLAKE|    30|\n",
      "| CLARK|    10|\n",
      "| SCOTT|    20|\n",
      "|  KING|    10|\n",
      "|TURNER|    30|\n",
      "| ADAMS|    20|\n",
      "| JAMES|    30|\n",
      "|  FORD|    20|\n",
      "|MILLER|    10|\n",
      "|  JACK|    70|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 대소문자구별 안함 \n",
    "emp_df.select('ENAME', 'DEPTNO').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad08bb3-202b-432f-b169-cc29b5fb7771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+----+----------+----+----+------+\n",
      "|empno|ename|    job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+-----+-------+----+----------+----+----+------+\n",
      "| 7369|SMITH|  CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "| 7566|JONES|MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7788|SCOTT|ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7876|ADAMS|  CLERK|7788|1987-05-23|1100|NULL|    20|\n",
      "| 7902| FORD|ANALYST|7566|1981-12-03|3000|NULL|    20|\n",
      "+-----+-----+-------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter() 와 동일함 \n",
    "emp_df.select('*').where('deptno=20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f24a9d61-fae6-4fea-875c-09663e9c39c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      15|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.selectExpr('count(*)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38b84b1e-b1d9-4ac8-a34c-e93cb187c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function 사용하면 더 빠름, api 확인 필요 \n",
    "from pyspark.sql.functions import countDistinct\n",
    "emp_df.select(countDistinct('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ddccd72-afcd-45f1-8860-00d711dad15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 오류율: 이 정도까지 허용 \n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "emp_df.select(approx_count_distinct('job', 0.1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96f707bf-4b41-4b54-91c6-60ed677e8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fist, last, min, max, sum, avg  -> expr쓰지 않고 function으로만 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079c53fa-25da-4e15-b84c-4ff1fa731591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, first, last, min, max, sum, avg, round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dfb3251-856c-437e-825a-4f2d787c6968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(sal)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(count(\"sal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bfe289c-1d37-49b9-85bb-97665a583372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|first(sal)|\n",
      "+----------+\n",
      "|       800|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first()\n",
    "emp_df.select(first('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12377b77-89d6-42df-b116-ba625b35aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|last(sal)|\n",
      "+---------+\n",
      "|     3200|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# last()\n",
    "emp_df.select(last('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95bbd63c-a4a5-4d76-a083-846348526ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(sal)|\n",
      "+--------+\n",
      "|     800|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min()\n",
    "emp_df.select(min('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c67d6f4-91c5-478c-861c-a5890b674bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(sal)|\n",
      "+--------+\n",
      "|    5000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max()\n",
    "emp_df.select(max('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e76cf92-e906-4c8e-9453-96e8556dc659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sum()\n",
    "emp_df.select(sum('sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9d0f363-c452-4cea-ad19-32f97921a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|round(avg(sal), 2)|\n",
      "+------------------+\n",
      "|           2148.33|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg()\n",
    "emp_df.select(round(avg('sal'), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a0d45de-0f83-4c4c-bbc8-51143754ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "emp_df.select(sum(col('sal'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e48464c-ed52-4b07-a95b-53627262cc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|            27975|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.selectExpr('sum(distinct sal)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e437938e-6921-443a-b123-bf2d4ac3bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------+-----------+\n",
      "|(total_salary / total_transaction)|avg_salary|mean_salary|\n",
      "+----------------------------------+----------+-----------+\n",
      "|                2148.3333333333335|    2148.0|     2148.0|\n",
      "+----------------------------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total_salary / total_transaction (salary의 count), avg_salary, mean_salary\n",
    "emp_df.select(\n",
    "    sum(\"sal\").alias(\"total_salary\"),\n",
    "    count(\"sal\").alias(\"total_transaction\"),\n",
    "    round(avg(\"sal\")).alias(\"avg_salary\"),\n",
    "    round(avg(\"sal\")).alias(\"mean_salary\")\n",
    ").selectExpr(\n",
    "    'total_salary/total_transaction',\n",
    "    'avg_salary',\n",
    "    'mean_salary'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2b8bf39-13f5-4157-b190-bc109e9cc9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그룹화 \n",
    "emp_df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6289bfd7-c1b5-4c58-b483-564ac9a97d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+--------+\n",
      "|      job|quantity|count(job)|sum(sal)|\n",
      "+---------+--------+----------+--------+\n",
      "|  ANALYST|       2|         2|    6000|\n",
      "| SALESMAN|       4|         4|    5600|\n",
      "|    CLERK|       5|         5|    7350|\n",
      "|  MANAGER|       3|         3|    8275|\n",
      "|PRESIDENT|       1|         1|    5000|\n",
      "+---------+--------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select job, \n",
    "#count(job),\n",
    "#sum(sal)\n",
    "#groupby job\n",
    "\n",
    "group_df = emp_df.groupBy('job').agg(\n",
    "    count('job').alias('quantity'),\n",
    "    expr('count(job)'),\n",
    "    sum('sal')\n",
    "    )\n",
    "\n",
    "group_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "395853e6-55d5-4d58-a020-4181974e7906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+\n",
      "|      job|SAL_AVG|SAL_STDEV|\n",
      "+---------+-------+---------+\n",
      "|  ANALYST| 3000.0|      0.0|\n",
      "| SALESMAN| 1400.0|   177.95|\n",
      "|    CLERK| 1470.0|   984.63|\n",
      "|  MANAGER|2758.33|   274.24|\n",
      "|PRESIDENT| 5000.0|     NULL|\n",
      "+---------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sal의 평균 SAL_AVG, 표준편차 SAL_STDEV 를 job별로 계산해서 출력, 소수점 2자리\n",
    "\n",
    "from pyspark.sql.functions import stddev\n",
    "\n",
    "emp_df.groupBy('job').agg(\n",
    "    round(avg('sal'), 2).alias(\"SAL_AVG\"),\n",
    "    round(stddev('sal'), 2).alias(\"SAL_STDEV\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd308714-98a0-4384-8f37-6c6eb4e0afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sal top10\n",
    "emp_df.orderBy(emp_df.sal.desc()).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baeb5f0e-cc8f-4b3a-9468-e43ca83d0e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 윈도우 함수 \n",
    "from pyspark.sql.window import Window \n",
    "from pyspark.sql.functions import desc, rank\n",
    "\n",
    "windowspec = Window.orderBy(desc('sal'))\n",
    "salAllRank = rank().over(windowspec)\n",
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cbc5c63-5edf-43b9-9e0e-9e11a0936bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6910dc78-3f37-4afb-8955-229baa5da2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|         10|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.withColumn('salary_rank', salAllRank).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beeceb76-f740-4186-b46e-3ac3392b519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+----+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|rank|\n",
      "+-----+------+---------+----+----------+----+----+------+----+\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|   1|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|   1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|   1|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|   2|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|   3|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|   4|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|   5|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|   1|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|   2|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|   3|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|   1|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|   1|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|   2|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|   3|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|   3|\n",
      "+-----+------+---------+----+----------+----+----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 직무별로 rank 작성\n",
    "# window.partitionBy()\n",
    "\n",
    "windowSpec = Window.partitionBy('job').orderBy(desc('sal'))\n",
    "\n",
    "# job_rank_df 작성 \n",
    "job_rank_df = emp_df.withColumn(\"rank\", rank().over(windowSpec))\n",
    "job_rank_df.orderBy('job', 'rank').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9790c6f8-ffa2-4352-8a48-ea9e726261b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+---------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|dept_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+---------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|        1|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|        2|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|        3|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|        1|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|        1|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|        3|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|        4|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|        5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|        1|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|        2|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|        3|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|        4|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|        4|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|        6|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|        1|\n",
      "+-----+------+---------+----+----------+----+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별순위\n",
    "window_rank = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "\n",
    "# emp_df에 순위 컬럼 추가\n",
    "emp_df.withColumn(\"dept_rank\", rank().over(window_rank)) \\\n",
    "      .orderBy(\"deptno\", \"dept_rank\") \\\n",
    "      .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c0006dd-af32-4a71-bf6f-bfb856f2d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|cum_salary|\n",
      "+-----+------+---------+----+----------+----+----+------+----------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|      5000|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|      7450|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|      8750|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|      3000|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|      6000|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|      8975|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|     10075|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|     10875|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|      2850|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|      4450|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|      5950|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|      7200|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|      8450|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|      9400|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|      3200|\n",
      "+-----+------+---------+----+----------+----+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 누적 급여 sum('sal').over()\n",
    "\n",
    "# 부서별 + 급여 내림차순으로 누적\n",
    "window_cum = Window.partitionBy(\"deptno\") \\\n",
    "                   .orderBy(desc(\"sal\")) \\\n",
    "                   .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "emp_df.withColumn(\"cum_salary\", sum(\"sal\").over(window_cum)) \\\n",
    "      .orderBy(\"deptno\", desc(\"sal\")) \\\n",
    "      .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e3f36d6-c233-4fe6-be9f-63f8094f0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|cum_salary|\n",
      "+-----+------+---------+----+----------+----+----+------+----------+\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|      5000|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|      7450|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|      8750|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|      3000|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|      6000|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|      8975|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|     10075|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|     10875|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|      2850|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|      4450|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|      5950|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|      7200|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|      8450|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|      9400|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|NULL|    70|      3200|\n",
      "+-----+------+---------+----+----------+----+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 누적급여\n",
    "\n",
    "# 부서별 누적합 윈도우 스펙\n",
    "window_cum = Window.partitionBy(\"deptno\") \\\n",
    "                   .orderBy(desc(\"sal\")) \\\n",
    "                   .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# 누적 급여 컬럼 추가\n",
    "emp_df.withColumn(\"cum_salary\", sum(\"sal\").over(window_cum)) \\\n",
    "      .orderBy(\"deptno\", desc(\"sal\")) \\\n",
    "      .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b9efa1f-5f27-4992-8fdf-fc76f3ef1a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|deptno|avg_salary|\n",
      "+------+----------+\n",
      "|    10|   2916.67|\n",
      "|    20|    2175.0|\n",
      "|    30|   1566.67|\n",
      "|    70|    3200.0|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 평균급여\n",
    "from pyspark.sql.functions import avg, round\n",
    "\n",
    "emp_df.groupBy(\"deptno\").agg(\n",
    "    round(avg(\"sal\"), 2).alias(\"avg_salary\")\n",
    ").orderBy(\"deptno\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0445e-a9eb-4b69-9942-d7d9544dfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부서별, 직업별 소계\n",
    "emp_df.groupBy('deptno', 'job').agg(count('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf7fcd4d-4026-4c16-a9ad-9bc1074d7d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  NULL|     NULL|      15|   32225|\n",
      "|  NULL|  ANALYST|       2|    6000|\n",
      "|  NULL|    CLERK|       5|    7350|\n",
      "|  NULL|  MANAGER|       3|    8275|\n",
      "|  NULL|PRESIDENT|       1|    5000|\n",
      "|  NULL| SALESMAN|       4|    5600|\n",
      "|    10|     NULL|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     NULL|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     NULL|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     NULL|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.cube('deptno', 'job').agg(count('*'),sum('sal'))\\\n",
    "    .orderBy('deptno', 'job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "813b6747-24f3-4fde-aa1b-2bb1fe846d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|NULL|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|    30|     SALES| CHICAGO|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|    30|     SALES| CHICAGO|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|NULL|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|    30|     SALES| CHICAGO|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|NULL|    30|    30|     SALES| CHICAGO|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|NULL|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|NULL|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7839|  KING|PRESIDENT|NULL|1981-11-17|5000|NULL|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|    30|     SALES| CHICAGO|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|NULL|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|NULL|    30|    30|     SALES| CHICAGO|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|NULL|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|NULL|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_dept_df = emp_df.join(dept_df, emp_df['deptno']==dept_df['deptno'])\n",
    "emp_dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac4fce70-1137-416e-904c-2625d7c4d6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+\n",
      "| ename|deptno|     dname|\n",
      "+------+------+----------+\n",
      "| SMITH|    20|  RESEARCH|\n",
      "| ALLEN|    30|     SALES|\n",
      "|  WARD|    30|     SALES|\n",
      "| JONES|    20|  RESEARCH|\n",
      "|MARTIN|    30|     SALES|\n",
      "| BLAKE|    30|     SALES|\n",
      "| CLARK|    10|ACCOUNTING|\n",
      "| SCOTT|    20|  RESEARCH|\n",
      "|  KING|    10|ACCOUNTING|\n",
      "|TURNER|    30|     SALES|\n",
      "| ADAMS|    20|  RESEARCH|\n",
      "| JAMES|    30|     SALES|\n",
      "|  FORD|    20|  RESEARCH|\n",
      "|MILLER|    10|ACCOUNTING|\n",
      "+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_df = emp_df.join(dept_df, on='deptno', how='inner')\n",
    "join_df.select('ename','deptno','dname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "398671e1-0add-4191-9629-6dcac4d8f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67183876-03cf-49d7-a7b9-94fdf36cf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
