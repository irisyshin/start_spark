{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad11f4d-9b65-4bed-82e5-0b935736aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b6032c2b5af4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>IBM_HR_parc</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe092fa7a50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('IBM_HR_parc').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e575bcfe-3817-4a2a-ac45-1433804044ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|Age|Attrition|   BusinessTravel|DailyRate|          Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|             JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n",
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "| 41|      Yes|    Travel_Rarely|     1102|               Sales|               1|        2| Life Sciences|            1|             1|                      2|Female|        94|             3|       2|     Sales Executive|              4|       Single|         5993|      19479|                 8|     Y|     Yes|               11|                3|                       1|           80|               0|                8|                    0|              1|             6|                 4|                      0|                   5|\n",
      "| 49|       No|Travel_Frequently|      279|Research & Develo...|               8|        1| Life Sciences|            1|             2|                      3|  Male|        61|             2|       2|  Research Scientist|              2|      Married|         5130|      24907|                 1|     Y|      No|               23|                4|                       4|           80|               1|               10|                    3|              3|            10|                 7|                      1|                   7|\n",
      "| 37|      Yes|    Travel_Rarely|     1373|Research & Develo...|               2|        2|         Other|            1|             4|                      4|  Male|        92|             2|       1|Laboratory Techni...|              3|       Single|         2090|       2396|                 6|     Y|     Yes|               15|                3|                       2|           80|               0|                7|                    3|              3|             0|                 0|                      0|                   0|\n",
      "| 33|       No|Travel_Frequently|     1392|Research & Develo...|               3|        4| Life Sciences|            1|             5|                      4|Female|        56|             3|       1|  Research Scientist|              3|      Married|         2909|      23159|                 1|     Y|     Yes|               11|                3|                       3|           80|               0|                8|                    3|              3|             8|                 7|                      3|                   0|\n",
      "| 27|       No|    Travel_Rarely|      591|Research & Develo...|               2|        1|       Medical|            1|             7|                      1|  Male|        40|             3|       1|Laboratory Techni...|              2|      Married|         3468|      16632|                 9|     Y|      No|               12|                3|                       4|           80|               1|                6|                    3|              3|             2|                 2|                      2|                   2|\n",
      "+---+---------+-----------------+---------+--------------------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+--------------------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = spark.read.format('csv')\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(os.path.join(cwd, \"learning_spark_data/HR-Employee-Attrition.csv\"))\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b36c7593-7a58-41a7-8640-fef45945284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Attrition: string (nullable = true)\n",
      " |-- BusinessTravel: string (nullable = true)\n",
      " |-- DailyRate: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- DistanceFromHome: integer (nullable = true)\n",
      " |-- Education: integer (nullable = true)\n",
      " |-- EducationField: string (nullable = true)\n",
      " |-- EmployeeCount: integer (nullable = true)\n",
      " |-- EmployeeNumber: integer (nullable = true)\n",
      " |-- EnvironmentSatisfaction: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- HourlyRate: integer (nullable = true)\n",
      " |-- JobInvolvement: integer (nullable = true)\n",
      " |-- JobLevel: integer (nullable = true)\n",
      " |-- JobRole: string (nullable = true)\n",
      " |-- JobSatisfaction: integer (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- MonthlyIncome: integer (nullable = true)\n",
      " |-- MonthlyRate: integer (nullable = true)\n",
      " |-- NumCompaniesWorked: integer (nullable = true)\n",
      " |-- Over18: string (nullable = true)\n",
      " |-- OverTime: string (nullable = true)\n",
      " |-- PercentSalaryHike: integer (nullable = true)\n",
      " |-- PerformanceRating: integer (nullable = true)\n",
      " |-- RelationshipSatisfaction: integer (nullable = true)\n",
      " |-- StandardHours: integer (nullable = true)\n",
      " |-- StockOptionLevel: integer (nullable = true)\n",
      " |-- TotalWorkingYears: integer (nullable = true)\n",
      " |-- TrainingTimesLastYear: integer (nullable = true)\n",
      " |-- WorkLifeBalance: integer (nullable = true)\n",
      " |-- YearsAtCompany: integer (nullable = true)\n",
      " |-- YearsInCurrentRole: integer (nullable = true)\n",
      " |-- YearsSinceLastPromotion: integer (nullable = true)\n",
      " |-- YearsWithCurrManager: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df 컬럼 이름, 타입 확인하기 \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0beee22b-5d28-4300-ade4-ec6cca171615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------+---------+----------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+-------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|Age|Attrition|BusinessTravel|DailyRate|Department|DistanceFromHome|Education|EducationField|EmployeeCount|EmployeeNumber|EnvironmentSatisfaction|Gender|HourlyRate|JobInvolvement|JobLevel|JobRole|JobSatisfaction|MaritalStatus|MonthlyIncome|MonthlyRate|NumCompaniesWorked|Over18|OverTime|PercentSalaryHike|PerformanceRating|RelationshipSatisfaction|StandardHours|StockOptionLevel|TotalWorkingYears|TrainingTimesLastYear|WorkLifeBalance|YearsAtCompany|YearsInCurrentRole|YearsSinceLastPromotion|YearsWithCurrManager|\n",
      "+---+---------+--------------+---------+----------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+-------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "|  0|        0|             0|        0|         0|               0|        0|             0|            0|             0|                      0|     0|         0|             0|       0|      0|              0|            0|            0|          0|                 0|     0|       0|                0|                0|                       0|            0|               0|                0|                    0|              0|             0|                 0|                      0|                   0|\n",
      "+---+---------+--------------+---------+----------+----------------+---------+--------------+-------------+--------------+-----------------------+------+----------+--------------+--------+-------+---------------+-------------+-------------+-----------+------------------+------+--------+-----------------+-----------------+------------------------+-------------+----------------+-----------------+---------------------+---------------+--------------+------------------+-----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인 \n",
    "from pyspark.sql.functions import col, sum as _sum\n",
    "\n",
    "null_counts = df.select([\n",
    "    _sum(col(c).isNull().cast('int')).alias(c) for c in df.columns\n",
    "])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811edbf9-fd82-4f78-8cc5-bca82e6d8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistanceFromHome, EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance, OverTime\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c6fac2-0ece-4a1b-afe2-c91464f09b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Attrition|count|\n",
      "+---------+-----+\n",
      "|       No| 1233|\n",
      "|      Yes|  237|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 퇴사 여부별 인원 수 \n",
    "df.groupBy(\"Attrition\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "036427cb-058d-45bd-bd42-b173e4367dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|Attrition|avg(MonthlyIncome)|\n",
      "+---------+------------------+\n",
      "|       No| 6832.739659367397|\n",
      "|      Yes|4787.0928270042195|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 퇴사 여부별 평균 급여\n",
    "df.groupBy(\"Attrition\").avg(\"MonthlyIncome\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83ae11cb-2627-4199-a59b-b5e78e507c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------------------------+\n",
      "|Attrition|             JobRole|avg(EnvironmentSatisfaction)|\n",
      "+---------+--------------------+----------------------------+\n",
      "|       No|Healthcare Repres...|           2.819672131147541|\n",
      "|       No|     Human Resources|                       2.675|\n",
      "|       No|Laboratory Techni...|          2.8223350253807107|\n",
      "|       No|             Manager|           2.814432989690722|\n",
      "|       No|Manufacturing Dir...|          2.9407407407407407|\n",
      "|       No|   Research Director|          2.4871794871794872|\n",
      "|       No|  Research Scientist|           2.746938775510204|\n",
      "|       No|     Sales Executive|          2.7323420074349443|\n",
      "|       No|Sales Representative|                        2.76|\n",
      "|      Yes|Healthcare Repres...|           2.111111111111111|\n",
      "|      Yes|     Human Resources|          2.3333333333333335|\n",
      "|      Yes|Laboratory Techni...|          2.3870967741935485|\n",
      "|      Yes|             Manager|                         1.8|\n",
      "|      Yes|Manufacturing Dir...|                         2.6|\n",
      "|      Yes|   Research Director|                         3.0|\n",
      "|      Yes|  Research Scientist|           2.617021276595745|\n",
      "|      Yes|     Sales Executive|          2.3859649122807016|\n",
      "|      Yes|Sales Representative|           2.696969696969697|\n",
      "+---------+--------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 퇴사여부 + 직무별 평균 환경 만족도 \n",
    "df.groupBy(\"Attrition\", \"JobRole\")\\\n",
    "     .avg(\"EnvironmentSatisfaction\")\\\n",
    "     .orderBy(\"Attrition\", \"JobRole\")\\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3635bec6-5f57-4e1a-84f8-0391405e1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8277944d-9b35-4716-a1bf-1d8ef30bb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "350dab06-c9f4-444a-b7b7-6ea59ecb9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟()encoding 0/1 no/yes\n",
    "label_indexer = StringIndexer(inputCol=\"Attrition\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fbe42d-db57-4bda-af67-6c06a31691a0",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "052b54a7-590f-4287-8bd9-7e0ab3e2d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 정리\n",
    "# 범주형 변수: 문자형 (One-Hot Encoding)\n",
    "categorical_cols = [\n",
    "    \"BusinessTravel\", \"Department\", \"EducationField\", \"Gender\",\n",
    "    \"JobRole\", \"MaritalStatus\", \"OverTime\"\n",
    "]\n",
    "\n",
    "# 수치형 변수\n",
    "numeric_cols = [\n",
    "    \"Age\", \"DistanceFromHome\", \"Education\", \"EnvironmentSatisfaction\",\n",
    "    \"HourlyRate\", \"JobInvolvement\", \"JobLevel\", \"JobSatisfaction\",\n",
    "    \"MonthlyIncome\", \"MonthlyRate\", \"NumCompaniesWorked\",\n",
    "    \"PercentSalaryHike\", \"PerformanceRating\", \"RelationshipSatisfaction\",\n",
    "    \"StockOptionLevel\", \"TotalWorkingYears\", \"TrainingTimesLastYear\",\n",
    "    \"WorkLifeBalance\", \"YearsAtCompany\", \"YearsInCurrentRole\",\n",
    "    \"YearsSinceLastPromotion\", \"YearsWithCurrManager\"\n",
    "]\n",
    "\n",
    "# 제거할 컬럼\n",
    "drop_cols = [\"EmployeeNumber\", \"Over18\", \"EmployeeCount\", \"StandardHours\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4dde8de-4203-42ae-8634-75e3c9add5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 컬럼 제거 \n",
    "hr_df_cleaned = df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beed7f4c-cff4-4717-a6f5-e0a83293a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.9406316051411292,0.0593683948588708] |\n",
      "|1.0  |1.0       |[0.03785200103867787,0.9621479989613221]|\n",
      "|0.0  |0.0       |[0.6543800334415575,0.3456199665584425] |\n",
      "|1.0  |0.0       |[0.7058231958589236,0.2941768041410764] |\n",
      "|0.0  |1.0       |[0.34369991611098155,0.6563000838890185]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 범주형 인코딩: StringIndexer → OneHotEncoder\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_idx\", handleInvalid='keep') for col in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCols=[col + \"_idx\"], outputCols=[col + \"_ohe\"]) for col in categorical_cols]\n",
    "\n",
    "# 4. 특성 벡터화\n",
    "assembler_inputs = [col + \"_ohe\" for col in categorical_cols] + numeric_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# 5. 로지스틱 회귀 모델\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# 6. 전체 파이프라인 구성\n",
    "pipeline = Pipeline(stages=indexers + encoders + [label_indexer, assembler, lr])\n",
    "\n",
    "# 7. 데이터 분할\n",
    "train_df, test_df = hr_df_cleaned.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 8. 파이프라인 학습\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# 9. 예측\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# 10. 결과 확인\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebc507e3-9f5e-4f4a-8b2c-5839da24c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 모델 평가 결과 ===\n",
      "AUC: 0.8046\n",
      "F1 Score: 0.8657\n",
      "Precision: 0.8766\n",
      "Recall: 0.8819\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# === 평가자 설정 ===\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "# === 결과 출력 ===\n",
    "print(\"=== 모델 평가 결과 ===\")\n",
    "print(f\"AUC: {evaluator_auc.evaluate(predictions):.4f}\")\n",
    "print(f\"F1 Score: {evaluator_f1.evaluate(predictions):.4f}\")\n",
    "print(f\"Precision: {evaluator_precision.evaluate(predictions):.4f}\")\n",
    "print(f\"Recall: {evaluator_recall.evaluate(predictions):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3d3c4-839f-47d7-b477-ee3cbbfed3f9",
   "metadata": {},
   "source": [
    "### Using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39693ffb-17de-4536-a85b-bd3c77226fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0.0  |0.0       |[0.5462181236385757,0.4537818763614243] |\n",
      "|1.0  |1.0       |[0.22133785436158349,0.7786621456384166]|\n",
      "|0.0  |1.0       |[0.4613048732895997,0.5386951267104003] |\n",
      "|1.0  |0.0       |[0.517420729681636,0.48257927031836395] |\n",
      "|0.0  |0.0       |[0.7673126688201038,0.2326873311798961] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "pipeline = Pipeline(stages=indexers + encoders + [label_indexer, assembler, rf])\n",
    "\n",
    "model = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "predictions.select(\"label\", \"prediction\", \"probability\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36b0f341-a27e-4d56-96ae-f0b967bf0a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8064\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aee0bf01-f74f-4c2d-88d9-5217d382324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "YearsSinceLastPromotion        → 0.0859\n",
      "YearsInCurrentRole             → 0.0740\n",
      "YearsWithCurrManager           → 0.0697\n",
      "WorkLifeBalance                → 0.0184\n",
      "Department_ohe                 → 0.0173\n",
      "RelationshipSatisfaction       → 0.0143\n",
      "JobRole_ohe                    → 0.0096\n",
      "Gender_ohe                     → 0.0088\n",
      "YearsAtCompany                 → 0.0085\n",
      "Education                      → 0.0084\n",
      "MonthlyRate                    → 0.0081\n",
      "DistanceFromHome               → 0.0076\n",
      "MonthlyIncome                  → 0.0066\n",
      "JobSatisfaction                → 0.0051\n",
      "OverTime_ohe                   → 0.0041\n",
      "JobLevel                       → 0.0040\n",
      "JobInvolvement                 → 0.0040\n",
      "TrainingTimesLastYear          → 0.0040\n",
      "TotalWorkingYears              → 0.0039\n",
      "HourlyRate                     → 0.0035\n",
      "MaritalStatus_ohe              → 0.0025\n",
      "Age                            → 0.0024\n",
      "StockOptionLevel               → 0.0024\n",
      "EducationField_ohe             → 0.0023\n",
      "NumCompaniesWorked             → 0.0020\n",
      "BusinessTravel_ohe             → 0.0018\n",
      "EnvironmentSatisfaction        → 0.0014\n",
      "PerformanceRating              → 0.0003\n",
      "PercentSalaryHike              → 0.0002\n"
     ]
    }
   ],
   "source": [
    "# 7. Feature Importance 출력\n",
    "rf_model = model.stages[-1]  # 파이프라인의 마지막 stage가 RandomForestClassifier\n",
    "importances = rf_model.featureImportances\n",
    "\n",
    "# Feature 이름 추출\n",
    "feature_names = assembler.getInputCols()\n",
    "\n",
    "# 중요도 매핑\n",
    "feature_importance_list = list(zip(feature_names, importances.toArray()))\n",
    "sorted_importance = sorted(feature_importance_list, key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in sorted_importance:\n",
    "    print(f\"{feature:30} → {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66cb25d-1382-44e7-b9c0-4c689480bbcd",
   "metadata": {},
   "source": [
    "###  Improved logistic regression\n",
    "중요도 매핑을 사용해 컬럼 선택 -> 새로운 모델 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1532f01-05ed-4127-b7a8-c520efc14933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC with selected features: 0.7235\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# 1. 제거할 컬럼\n",
    "drop_cols = [\"EmployeeNumber\", \"Over18\", \"EmployeeCount\", \"StandardHours\"]\n",
    "df_new = df.drop(*drop_cols)\n",
    "\n",
    "# 2. Label 생성 (Yes → 1, No → 0)\n",
    "df_new = df_new.withColumn(\"label\", when(col(\"Attrition\") == \"Yes\", 1).otherwise(0))\n",
    "\n",
    "# 3. 중요 Feature 목록\n",
    "important_features = [\n",
    "    \"YearsInCurrentRole\", \"YearsSinceLastPromotion\", \"YearsWithCurrManager\",\n",
    "    \"WorkLifeBalance\", \"Department\", \"MonthlyRate\", \"RelationshipSatisfaction\",\n",
    "    \"MonthlyIncome\", \"JobRole\", \"Gender\", \"Education\", \"DistanceFromHome\"\n",
    "]\n",
    "\n",
    "# 4. 범주형 vs 수치형 구분\n",
    "categorical_cols = [\"Department\", \"JobRole\", \"Gender\"]\n",
    "numeric_cols = [col for col in important_features if col not in categorical_cols]\n",
    "\n",
    "# 5. Train/Test Split\n",
    "train_df, test_df = df_new.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "# 6. Indexing + OneHotEncoding\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid='keep') for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCols=[c + \"_idx\"], outputCols=[c + \"_ohe\"]) for c in categorical_cols]\n",
    "\n",
    "# 7. Assemble features\n",
    "assembler_inputs = [c + \"_ohe\" for c in categorical_cols] + numeric_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# 8. Logistic Regression\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# 9. Pipeline 구성\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n",
    "\n",
    "# 10. 학습 및 예측\n",
    "model = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# 11. 평가\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"AUC with selected features: {auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
